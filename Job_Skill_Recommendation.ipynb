{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "Wt6_xIGF4Rbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import spacy\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "# from spacy.gold import GoldParse\n",
        "from spacy.training import offsets_to_biluo_tags\n",
        "from spacy.scorer import Scorer\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "VHAKv7fq4UpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting dataturks to spacy format"
      ],
      "metadata": {
        "id": "lfPoMz4t4ZmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting dataturks annotated data to spacy format to be\n",
        "#used as training data\n",
        "\n",
        "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
        "    try:\n",
        "        training_data = []\n",
        "        lines=[]\n",
        "        with open(dataturks_JSON_FilePath, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            data = json.loads(line)\n",
        "            text = data['content']\n",
        "            entities = []\n",
        "            for annotation in data['annotation']:\n",
        "                #only a single point in text annotation.\n",
        "                point = annotation['points'][0]\n",
        "                labels = annotation['label']\n",
        "                # handle both list of labels or a single label.\n",
        "                if not isinstance(labels, list):\n",
        "                    labels = [labels]\n",
        "\n",
        "                for label in labels:\n",
        "                    #dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
        "                    entities.append((point['start'], point['end'] + 1 ,label))\n",
        "\n",
        "\n",
        "            training_data.append((text, {\"entities\" : entities}))\n",
        "\n",
        "        return training_data\n",
        "    except Exception as e:\n",
        "        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\n",
        "        return None"
      ],
      "metadata": {
        "id": "28Hh6Dg84eiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning data"
      ],
      "metadata": {
        "id": "iQ225Q7Y4hyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removes leading and trailing white spaces from entity spans.#\n",
        "def trim_entity_spans(data: list) -> list:\n",
        "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
        "\n",
        "    Args:\n",
        "        data (list): The data to be cleaned in spaCy JSON format.\n",
        "\n",
        "    Returns:\n",
        "        list: The cleaned data.\n",
        "    \"\"\"\n",
        "    invalid_span_tokens = re.compile(r'\\s')\n",
        "\n",
        "    cleaned_data = []\n",
        "    for text, annotations in data:\n",
        "        entities = annotations['entities']\n",
        "        valid_entities = []\n",
        "        for start, end, label in entities:\n",
        "            valid_start = start\n",
        "            valid_end = end\n",
        "            while valid_start < len(text) and invalid_span_tokens.match(\n",
        "                    text[valid_start]):\n",
        "                valid_start += 1\n",
        "            while valid_end > 1 and invalid_span_tokens.match(\n",
        "                    text[valid_end - 1]):\n",
        "                valid_end -= 1\n",
        "            valid_entities.append([valid_start, valid_end, label])\n",
        "        cleaned_data.append([text, {'entities': valid_entities}])\n",
        "\n",
        "    return cleaned_data"
      ],
      "metadata": {
        "id": "DDUuc7T34qE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "FZxRyJF7443q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Spacy NER.#\n",
        "def train_spacy():\n",
        "    TRAIN_DATA = convert_dataturks_to_spacy(\"/content/drive/MyDrive/five_class_entitydata/traindata_3withmyannotation.json\")\n",
        "    TRAIN_DATA=trim_entity_spans(TRAIN_DATA)\n",
        "    nlp = spacy.blank('en')  # create blank Language class\n",
        "    # create the built-in pipeline components and add them to the pipeline\n",
        "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
        "    # if 'tagger' not in nlp.pipe_names:\n",
        "    #      nlp.add_pipe(nlp.create_pipe('tagger'))\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner=nlp.add_pipe('ner')\n",
        "\n",
        "\n",
        "\n",
        "    # add labels\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "         for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    # get names of other pipes to disable them during training\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(25):\n",
        "            print(\"Statring iteration \" + str(itn))\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            for text, annotations in TRAIN_DATA:\n",
        "                nlp.update(\n",
        "                    text,  # batch of texts\n",
        "                    annotations,  # batch of annotations\n",
        "                    drop=0.1,  # dropout - make it harder to memorise data\n",
        "                    sgd=optimizer,  # callable to update weights\n",
        "                    losses=losses)\n",
        "            print(losses)\n",
        "    return nlp"
      ],
      "metadata": {
        "id": "_w0PVyDb4-uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nlp_= train_spacy()\n",
        "train_spacy()"
      ],
      "metadata": {
        "id": "m7FBpnzE5UE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the Trained model"
      ],
      "metadata": {
        "id": "6jKsTxlO5XJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save model to output directory (with parcial cleaned data)\n",
        "def save_model(output_dir):\n",
        "      nlp_.to_disk(output_dir)\n",
        "      print(\"Saved model to\", output_dir)"
      ],
      "metadata": {
        "id": "j_m3QVN55bg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir='./model2'\n",
        "save_model(output_dir)"
      ],
      "metadata": {
        "id": "KlfzIJOr5enR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the trained model instance"
      ],
      "metadata": {
        "id": "dLfbSNn85gzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #loading the saved model#\n",
        " output_dir='./model2'\n",
        " nlp2 = spacy.load(output_dir)"
      ],
      "metadata": {
        "id": "gjf3wXLv5klH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "3X2nWAd65o--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing the testdata#\n",
        "examples = convert_dataturks_to_spacy(\"3class_test_data.json\")\n",
        "examples=trim_entity_spans(examples)\n",
        "tp = 0\n",
        "tr = 0\n",
        "tf = 0\n",
        "\n",
        "ta = 0\n",
        "c = 0"
      ],
      "metadata": {
        "id": "HizUgjUO5tu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the model#\n",
        "nlp_=nlp2\n",
        "for text, annot in examples:\n",
        "\n",
        "    f = open(\"resume\"+str(c)+\".txt\", \"w\")\n",
        "    doc_to_test = nlp_(text)\n",
        "    d = {}\n",
        "    for ent in doc_to_test.ents:\n",
        "        d[ent.label_] = []\n",
        "    for ent in doc_to_test.ents:\n",
        "        d[ent.label_].append(ent.text)\n",
        "\n",
        "    if 'Skills' in d:\n",
        "      skills_=d['Skills']\n",
        "      print(f'resume {str(c)} skills {skills_}')\n",
        "    # print(d.keys())\n",
        "\n",
        "    #---------------------------\n",
        "    for i in set(d.keys()):\n",
        "\n",
        "        f.write(\"\\n\\n\")\n",
        "        f.write(i + \":\"+\"\\n\")\n",
        "        for j in set(d[i]):\n",
        "            f.write(j.replace('\\n', '')+\"\\n\")\n",
        "    #-----------------------------\n",
        "    d = {}\n",
        "    for ent in doc_to_test.ents:\n",
        "        d[ent.label_] = [0, 0, 0, 0, 0, 0]\n",
        "    for ent in doc_to_test.ents:\n",
        "        doc_gold_text = nlp_.make_doc(text)\n",
        "        gold = GoldParse(doc_gold_text, entities=annot.get(\"entities\"))\n",
        "        y_true = [ent.label_ if ent.label_ in x else 'Not ' +\n",
        "                  ent.label_ for x in gold.ner]\n",
        "        y_pred = [x.ent_type_ if x.ent_type_ ==\n",
        "                  ent.label_ else 'Not '+ent.label_ for x in doc_to_test]\n",
        "        if(d[ent.label_][0] == 0):\n",
        "            # f.write(\"For Entity \"+ent.label_+\"\\n\")\n",
        "            # f.write(classification_report(y_true, y_pred)+\"\\n\")\n",
        "            (p, r, f, s) = precision_recall_fscore_support(\n",
        "                y_true, y_pred, average='weighted')\n",
        "            a = accuracy_score(y_true, y_pred)\n",
        "            d[ent.label_][0] = 1\n",
        "            d[ent.label_][1] += p\n",
        "            d[ent.label_][2] += r\n",
        "            d[ent.label_][3] += f\n",
        "            d[ent.label_][4] += a\n",
        "            d[ent.label_][5] += 1\n",
        "    c += 1"
      ],
      "metadata": {
        "id": "qau884QX526p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validating the prediction"
      ],
      "metadata": {
        "id": "GVs_JzE_7Onz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating the model#\n",
        "for i in d:\n",
        "    print(\"\\n For Entity \"+i+\"\\n\")\n",
        "    print(\"Accuracy : \"+str((d[i][4]/d[i][5])*100)+\"%\")\n",
        "    print(\"Precision : \"+str(d[i][1]/d[i][5]))\n",
        "    print(\"Recall : \"+str(d[i][2]/d[i][5]))\n",
        "    print(\"F-score : \"+str(d[i][3]/d[i][5]))"
      ],
      "metadata": {
        "id": "DEcjJ30J7VU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matcher"
      ],
      "metadata": {
        "id": "mXwH-tQs7baT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create jobs list\n",
        "jobs=[]\n",
        "job_dir='/content/drive/My Drive/five_class_entitydata/jobs'\n",
        "pathlist = Path(job_dir).glob('**/*.txt')\n",
        "for path in pathlist:\n",
        "    with open (path, \"r\") as fileHandler:\n",
        "      job={\n",
        "          'name':path.name,\n",
        "           'skills':find_skills(''.join(fileHandler.readlines()))\n",
        "      }\n",
        "      jobs.append(job)"
      ],
      "metadata": {
        "id": "lYoFwqiw7eUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(jobs[1]['name'])\n",
        "print(jobs[1]['skills'])\n",
        "print(jobs[2]['name'])\n",
        "print(jobs[2]['skills'])\n",
        "print(jobs[3]['name'])\n",
        "print(jobs[3]['skills'])\n",
        "print(jobs[4]['name'])\n",
        "print(jobs[4]['skills'])"
      ],
      "metadata": {
        "id": "eKjpx2hH7jcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating CV List"
      ],
      "metadata": {
        "id": "Zi88-OU17oeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create cvs list\n",
        "cvs=[]\n",
        "cv_dir='/content/drive/My Drive/five_class_entitydata/cv'\n",
        "pathlist = Path(cv_dir).glob('**/*.txt')\n",
        "for path in pathlist:\n",
        "    with open (path, \"r\") as files:\n",
        "      cv={\n",
        "          'name':path.name,\n",
        "           'skills':find_skills(''.join(files.readlines()))\n",
        "      }\n",
        "      cvs.append(cv)"
      ],
      "metadata": {
        "id": "4PvXOPtB7vtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cvs[1]['name'])\n",
        "print(cvs[1]['skills'])\n",
        "print(cvs[2]['name'])\n",
        "print(cvs[2]['skills'])\n",
        "print(cvs[3]['name'])\n",
        "print(cvs[3]['skills'])\n",
        "print(cvs[4]['name'])\n",
        "print(cvs[4]['skills'])\n",
        "print(cvs[5]['name'])\n",
        "print(cvs[5]['skills'])"
      ],
      "metadata": {
        "id": "4C3AC02170zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matching both list cv and jobs"
      ],
      "metadata": {
        "id": "qR8bBHbN72dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def job_match(text,cv=True):\n",
        "  skills=find_skills(text)\n",
        "  matched=[]\n",
        "  if cv:\n",
        "    for job in jobs:\n",
        "      nskill_job=len(job['skills'])\n",
        "      count=0\n",
        "      for skill in skills:\n",
        "        if skill in job['skills']:\n",
        "          count+=1\n",
        "      matched.append({\n",
        "          'name':job['name'],\n",
        "          'pct':count/nskill_job*100,\n",
        "          'job_skill':job['skills'],\n",
        "          'cv_skill':skills\n",
        "\n",
        "      })\n",
        "  else:\n",
        "    for cv in cvs:\n",
        "      nskill_cv=len(cv['skills'])\n",
        "      count=0\n",
        "      for skill in skills:\n",
        "        if skill in cv['skills']:\n",
        "          count+=1\n",
        "      matched.append({\n",
        "          'name':cv['name'],\n",
        "          'pct':count/nskill_cv*100,\n",
        "          'job_skill':cv['skills'],\n",
        "          'cv_skill':skills\n",
        "\n",
        "      })\n",
        "  return matched"
      ],
      "metadata": {
        "id": "GDnH0qZU75ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding Most Matching Job"
      ],
      "metadata": {
        "id": "lZc41RE179rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find most matching jobs\n",
        "#reading the file from folder#\n",
        "f = open('/content/drive/My Drive/five_class_entitydata/cv/r1.txt', 'r')\n",
        "text = f.read()\n",
        "match_jobs=job_match(text)\n",
        "match_jobs = sorted(match_jobs, key=lambda k: k['pct'],reverse=True)"
      ],
      "metadata": {
        "id": "tju9s6eE8AUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  print(f\"cv matching with {match_jobs[i]['name']}\")\n",
        "  print(f\"{match_jobs[i]['pct']}\")"
      ],
      "metadata": {
        "id": "0Q0SSQbm8GSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding Most Matching Resumes"
      ],
      "metadata": {
        "id": "UyghuN6k8Jn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find most matching cv\n",
        "#reading the file from folder#\n",
        "f = open('/content/drive/My Drive/five_class_entitydata/jobs/dataengineer.txt', 'r')\n",
        "text = f.read()\n",
        "match_cvs=job_match(text,cv=False)\n",
        "match_cvs = sorted(match_cvs, key=lambda k: k['pct'],reverse=True)"
      ],
      "metadata": {
        "id": "ODKpx8FP8LFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(f\"job matching with cv {match_cvs[i]['name']}\")\n",
        "  print(f\"{match_cvs[i]['pct']}\")"
      ],
      "metadata": {
        "id": "R9HfSDPs8RzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleanups"
      ],
      "metadata": {
        "id": "fNzgRuMt8UmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#delete produced resume files#\n",
        "i=10\n",
        "while i < 30:\n",
        "  print (\"resume\"+str(i)+\".txt\")\n",
        "  if os.path.isfile(\"resume\"+str(i)+\".txt\"):\n",
        "    print (\"found\")\n",
        "    path = \"resume\"+str(i)+\".txt\"\n",
        "    os.remove(path)\n",
        "    print (\"deleted\")\n",
        "    print (\"..........\")\n",
        "  else:\n",
        "    print (\"not found\")\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "RuhopHl68XGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8iNtTnoK4PiA"
      }
    }
  ]
}